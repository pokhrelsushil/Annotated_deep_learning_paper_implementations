{
 "<h1>Fixed Positional Encodings</h1>\n<p>The positional encoding encodes the position along the sequence into  a vector of size <span translate=no>_^_0_^_</span>.</p>\n<span translate=no>_^_1_^_</span><p>Where <span translate=no>_^_2_^_</span>  are the feature indexes in the encoding, and <span translate=no>_^_3_^_</span> is the position.</p>\n": "<h1>\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801</h1>\n<p>\u4f4d\u7f6e\u7f16\u7801\u5c06\u6cbf\u5e8f\u5217\u7684\u4f4d\u7f6e\u7f16\u7801\u4e3a\u5927\u5c0f\u5411\u91cf<span translate=no>_^_0_^_</span>\u3002</p>\n<span translate=no>_^_1_^_</span><p>\u7f16\u7801<span translate=no>_^_2_^_</span>\u4e2d\u7684\u7279\u5f81\u7d22\u5f15\u5728\u54ea\u91cc\uff0c<span translate=no>_^_3_^_</span>\u662f\u4f4d\u7f6e\u3002</p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>Add batch dimension </p>\n": "<p>\u589e\u52a0\u6279\u5904\u7406\u7ef4\u5ea6</p>\n",
 "<p>Empty encodings vectors </p>\n": "<p>\u7a7a\u7f16\u7801\u5411\u91cf</p>\n",
 "<p>Position indexes </p>\n": "<p>\u4f4d\u7f6e\u7d22\u5f15</p>\n",
 "Fixed Positional Encodings": "\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801",
 "Implementation with explanation of fixed positional encodings as described in paper Attention is All You Need.": "\u6839\u636e\u8bba\u6587\u300a Attention is All You Need\u300b\u63cf\u8ff0\u7684\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801\u7684\u89e3\u91ca\u4e0e\u5b9e\u73b0\u3002"
}